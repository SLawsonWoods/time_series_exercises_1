{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting \n",
    "\n",
    "![extrapolating](https://imgs.xkcd.com/comics/extrapolating.png)\n",
    "\n",
    "In this lesson, we will practice forecasting using the following methods:  \n",
    "\n",
    "- Last observed value  \n",
    "- Simple average  \n",
    "- Moving average  \n",
    "- Holt's Linear Trend  \n",
    "- Previous cycle  \n",
    "\n",
    "\n",
    "______________________________\n",
    "\n",
    "\n",
    "We will walk through steps from previous lessons to get the data ready to model\n",
    "\n",
    "- Acquire data: prepare.acquire_store_data()  \n",
    "- Prepare data: prepare.prep_store_data()  \n",
    "- Split data: prepare.split_store_data()  \n",
    "\n",
    "Then we will forecast and evaluate using each method. \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import env\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import Holt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire\n",
    "\n",
    "We will acquire the store-item-demand data for this lesson from the sql database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define get_connection\n",
    "df = env.get_tsa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign query to variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sql query using pd.read_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_upc14</th>\n",
       "      <th>item_upc12</th>\n",
       "      <th>item_brand</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_price</th>\n",
       "      <th>sale_id</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>store_address</th>\n",
       "      <th>store_zipcode</th>\n",
       "      <th>store_city</th>\n",
       "      <th>store_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>13</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>78253</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>11</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>78253</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>14</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>78253</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>78253</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>78253</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id  item_id   item_upc14   item_upc12 item_brand  \\\n",
       "0         1        1  35200264013  35200264013   Riceland   \n",
       "1         1        1  35200264013  35200264013   Riceland   \n",
       "2         1        1  35200264013  35200264013   Riceland   \n",
       "3         1        1  35200264013  35200264013   Riceland   \n",
       "4         1        1  35200264013  35200264013   Riceland   \n",
       "\n",
       "                        item_name  item_price  sale_id   sale_date  \\\n",
       "0  Riceland American Jazmine Rice        0.84        1  2013-01-01   \n",
       "1  Riceland American Jazmine Rice        0.84        2  2013-01-02   \n",
       "2  Riceland American Jazmine Rice        0.84        3  2013-01-03   \n",
       "3  Riceland American Jazmine Rice        0.84        4  2013-01-04   \n",
       "4  Riceland American Jazmine Rice        0.84        5  2013-01-05   \n",
       "\n",
       "   sale_amount           store_address store_zipcode   store_city store_state  \n",
       "0           13  12125 Alamo Ranch Pkwy         78253  San Antonio          TX  \n",
       "1           11  12125 Alamo Ranch Pkwy         78253  San Antonio          TX  \n",
       "2           14  12125 Alamo Ranch Pkwy         78253  San Antonio          TX  \n",
       "3           13  12125 Alamo Ranch Pkwy         78253  San Antonio          TX  \n",
       "4           10  12125 Alamo Ranch Pkwy         78253  San Antonio          TX  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. sale_date to datetime\n",
    "2. sort values by date\n",
    "3. set index\n",
    "4. new field: dollars_sold = sale_amount * item_price\n",
    "5. rename sale_amount to items_sold to make the two columns easier to understand what the data represents. \n",
    "6. resample daily (The original granularity is daily, but there are multiple records of the same days across multiple stores.)\n",
    "7. remove leap days!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sale_date to datetime\n",
    "df = df.assign(ds= pd.to_datetime(df.sale_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dollars_sold</th>\n",
       "      <th>item_sold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>73844.01</td>\n",
       "      <td>13696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>73570.58</td>\n",
       "      <td>13678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>78169.48</td>\n",
       "      <td>14488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>84467.73</td>\n",
       "      <td>15677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>87621.85</td>\n",
       "      <td>16237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dollars_sold  item_sold\n",
       "ds                                 \n",
       "2013-01-01      73844.01      13696\n",
       "2013-01-02      73570.58      13678\n",
       "2013-01-03      78169.48      14488\n",
       "2013-01-04      84467.73      15677\n",
       "2013-01-05      87621.85      16237"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values by date\n",
    "df = df.sort_values('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dollars_sold = sale_amount * item_price\n",
    "df = df.assign(dollars_sold = df.sale_amount * df.item_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dollars_sold</th>\n",
       "      <th>item_sold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>73844.01</td>\n",
       "      <td>13696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>73570.58</td>\n",
       "      <td>13678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>78169.48</td>\n",
       "      <td>14488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>84467.73</td>\n",
       "      <td>15677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>87621.85</td>\n",
       "      <td>16237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dollars_sold  item_sold\n",
       "ds                                 \n",
       "2013-01-01      73844.01      13696\n",
       "2013-01-02      73570.58      13678\n",
       "2013-01-03      78169.48      14488\n",
       "2013-01-04      84467.73      15677\n",
       "2013-01-05      87621.85      16237"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create items_sold from sale_amount (rename)\n",
    "df =df.assign(item_sold = df.sale_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample daily, assumming dollars_sold and items_sold\n",
    "df = df.groupby(['ds'])[['dollars_sold', 'item_sold']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index\n",
    "#df.set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-12-3c6d437ee409>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-3c6d437ee409>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    assign(dollars_sold = df.sale_amount * df.item_price).\\ # gets you total sales\u001b[0m\n\u001b[0m                                                                                  \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "def prep_data(df):\n",
    "    return df.assign(ds= pd.to_datetime(df.sale_date)).sort_values('ds').\\\n",
    "    assign(dollars_sold = df.sale_amount * df.item_price).\\ # gets you total sales\n",
    "    assign(item_sold = df.sale_amount).\\  # renames the column\n",
    "    df.groupby(['ds'])[['dollars_sold', 'item_sold']].sum() # this is like a resample by day\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leap days by takin that day out of the index\n",
    "df = df[df.index != '2016-02-29']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will resample to daily, but essentially what we are doing is grouping by the day and aggregating using sum. The original granularity is daily, but there are multiple records of the same days across multiple stores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "1. We will use the training proportion method to split.    \n",
    "2. Identify the total length of the dataframe and multiple by `train_prop` to get the number of rows that equates to the first x% of the dataframe, which equates to the first x% of the time covered in the data.   (`x = train_prop * 100`)  \n",
    "3. Select row indices from 0 up to the index representing x-percentile for train, and from the index representing x-percentile through the end of the dataframe for test. In both of these, we will reset the index in order to return dataframes sorted by datetime.  \n",
    "4. Return train and test dataframes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size = len(df)\n",
    "df_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute num of rows that are 50% of total rows and assign to variable train_size\n",
    "train_size = int(len(df)* .5)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute num of rows that are 30% of total rows and assign to variable validate_size\n",
    "validate_size = int(len(df) * .3)\n",
    "validate_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test_size the number of rows remaining (test_size = total # of rows - train_size - validate_size)\n",
    "test_size = int(len(df)- train_size - validate_size)\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the row number at which the switch from validate to test happens. \n",
    "validate_end_index = train_size + validate_size\n",
    "validate_end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation, test\n",
    "train = df[: train_size] # all rows until 912\n",
    "validate = df[train_size : validate_end_index] 912 to 1459\n",
    "test = df[validate_end_index :]# 1459 to (1825-1459)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Verify Splits**\n",
    "\n",
    "Does the length of each df equate to the length of the original df? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of train, validate and test = total number of rows? \n",
    "len(train) + len(validate) + len(test) == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the first row of original df equate to the first row of train? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the row starts\n",
    "print(df.head(1)== train.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the last row of train the day before the first row of validate? And the same for validate to test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the split between validate and test\n",
    "pd.concat([train.tail(1), validate.head(1)]) # the results should be in order from one day to next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([validate.tail(1), test.head(1)]) # the results should be in order from one day to next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the last row of test the same as the last row of our original dataframe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the last row of test to last row of df\n",
    "pd.concat([test.tail(1), df.tail(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our data first, viewing where the data is split into train, validate, and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(target_var):\n",
    "    ''' this function will plot the train, validate and test values for a single variable \n",
    "    '''\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[target_var])\n",
    "    plt.plot(validate[target_var])\n",
    "    plt.plot(test[target_var])\n",
    "    plt.title(target_var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data points, color by train, validate, test\n",
    "#col = 'dollars_sold'\n",
    "for col in train.columns:\n",
    "    plot_samples(col)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try out different methods for forecasting sales and number of items sold, let's create a couple of functions that will be helpful in evaluating each of the methods that follow. \n",
    "\n",
    "`evaluate()` will compute the Mean Squared Error and the Rood Mean Squared Error to evaluate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation function to compute rmse\n",
    "\n",
    "def evaluate(target_var):\n",
    "    '''\n",
    "    the evaluate function will take in the actual values in the validate and the predicted values\n",
    "    '''\n",
    "    rmse = round(sqrt(mean_squared_error(validate[target_var], yhat_df[target_var])), 0)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_and_eval()` will use the evaluate function and also plot train and test values with the predicted values in order to compare performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and evaluate: plot\n",
    "def plot_and_eval(target_var):\n",
    "    '''\n",
    "    a function to evaluate forecasts by computing the rmse and plot train and validate along with predictions\n",
    "    '''\n",
    "    plot_samples(target_var)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var)\n",
    "    print(target_var, '--RMSE:  {: 0f}'.format(rmse))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write `append_eval_df(model_type)` to append evaluation metrics for each model type, target variable, and metric type, along with the metric value into our `eval_df` data frame object. Which we will create an empty `eval_df` dataframe object to start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the empty dataframe with model_type, target_var, rmse\n",
    "eval_df = pd.DataFrame(columns = ['model_type', 'target_var','rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the data frame\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to store rmse for comparison purposes\n",
    "def append_eval_df(model_type, target_var):\n",
    "    '''\n",
    "    this function is going to take in the model_type as a string, the target variable as a string,\n",
    "    and run the evaluate() function to compute the rmse,\n",
    "    and append to the dataframe a row with the model_type, target_var, and rmse. \n",
    "    It will return the new dataframe.\n",
    "    '''\n",
    "    rmse = evaluate(target_var)\n",
    "    d = {'model_type': [model_type], 'target_var': [target_var], 'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast \n",
    "\n",
    "### Last observed value\n",
    "\n",
    "The simplest method for forecasting is to predict all future values to be the last observed value.  \n",
    "\n",
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create var 'items' with last observed value\n",
    "items = train['item_sold'][-1]\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dollars 'items' with last observed value\n",
    "dollars = round(train['dollars_sold'][-1],2)\n",
    "dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by adding those values to new dataframe yhat_df\n",
    "yhat_df = pd.DataFrame({'item_sold': [items], 'dollars_sold': [dollars]}, index = validate.index)\n",
    "yhat_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, when peeking into yhat_df, that every predicted value is the same.  \n",
    "\n",
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate** \n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'last_observed_value', target_var = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Average\n",
    "\n",
    "Take the simple average of historical values and use that value to predict future values.   \n",
    "\n",
    "This is a good option for an initial baseline. Every future datapoint (those in 'test') will be assigned the same value, and that value will be the overall mean of the values in train. \n",
    "\n",
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = round(train['item_sold'].mean(), 2)\n",
    "dollars = round(train['dollars_sold'].mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(items, dollars):\n",
    "    yhat_df = pd.DataFrame({'item_sold': [items], 'dollars_sold':[dollars]}, index = validate.index)\n",
    "    return yhat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot and evaluate the performance of our time series model using **Simple Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = make_predictions(items, dollars)\n",
    "yhat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**\n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average\n",
    "\n",
    "In this example, we will use a 30-day moving average to forecast. In other words, the average over the last 30-days will be used as the forecasted value. \n",
    "\n",
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = make_predictions(items, dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot and evaluate the performance of our time series model using **Moving Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 30\n",
    "items = round(train['item_sold'].rolling(period).mean().iloc[-1])\n",
    "dollars = round(train['dollars_sold'].rolling(period).mean().iloc[-1])\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**\n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type=\"30d moving average\", target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the evaluation results to our eval_df for each target variable so we can \n",
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = '30d moving average', target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_df[eval_df.target_var == 'dollars sold']\n",
    "#eval_df[eval_df.target_vaar == 'item_sold']\n",
    "\n",
    "#find the min value\n",
    "eval_df_sort_values(by=['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out several other values for periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 200\n",
    "items = round(train['item_sold'].rolling(period).mean().iloc[-1])\n",
    "dollars = round(train['dollars_sold'].rolling(period).mean().iloc[-1])\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 15\n",
    "items = round(train['item_sold'].rolling(period).mean().iloc[-1])\n",
    "dollars = round(train['dollars_sold'].rolling(period).mean().iloc[-1], 2)\n",
    "yhat_df = make_predictions(items, dollars)\n",
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type=\"15d moving average\", target_var = col)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is best so far? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the min rmse for each variable\n",
    "eval_df.sort_values(by=['rmse']).groupby('target_var').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only the rows that match those rmse to find out \n",
    "# which models are best thus far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt's Linear Trend\n",
    "\n",
    "Exponential smoothing applied to both the average and the trend (slope).  \n",
    "\n",
    "- $\\alpha$ / smoothing_level: smoothing parameter for mean. Values closer to 1 will have less of a smoothing effect and will give greater weight to recent values.   \n",
    "- $\\beta$ / smoothing_slope: smoothing parameter for the slope. Values closer to 1 will give greater weight to recent slope/values. \n",
    "\n",
    "\n",
    "**Seasonal Decomposition**\n",
    "\n",
    "First, let's take a look at the seasonal decomposition for each target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "for col in train.columns:\n",
    "    print(col, '\\n')\n",
    "    _ = sm.tsa.seasonal_decompose(train[col].resample('W').mean()).plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Holt's Linear Trend\n",
    "\n",
    "**Make Predictions**\n",
    "\n",
    "Now, like we would when using sklearn, we will create the Holt object, fit the model, and make predictions. \n",
    "\n",
    "Holt: \n",
    "\n",
    "- exponential = True/False (exponential vs. linear growth, additive vs. multiplicative)\n",
    "\n",
    "fit: \n",
    "\n",
    "- smoothing_level ($\\alpha$): value between (0,1)\n",
    "- smoothing_slope ($\\beta$): value between (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    # Making the model\n",
    "    model = Holt(train[col], exponential = False)\n",
    "    \n",
    "    # Fitting the model\n",
    "    model = model.fit(smoothing_level = .5, smoothing_slope = .5, optimized = False)\n",
    "    \n",
    "    # Making predictions \n",
    "    yhat = model.predict(start = validate.index[0], end = validate.index[-1])\n",
    "    \n",
    "    yhat_df[col] = round(yhat, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in train.columns:\n",
    "#     model = Holt(train['item_sold'], exponential = False)\n",
    "\n",
    "#     model = model.fit(smoothing_level = .5, \n",
    "#                  smoothing_slope = .5,\n",
    "#                  optimized = False)\n",
    "#     # predict/forecast providing the start and end dates\n",
    "#     yhat_items = model.predict(start = validate.index[0], end = validate.index[-1])\n",
    "    \n",
    "#     yhat_df[col] = round(yhat, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "        eval_df = append_eval_df(model_type = 'Holts', target_var = col)\n",
    "        plot_and_eval(target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    # Making the model\n",
    "    model = Holt(train[col], exponential = False)\n",
    "    \n",
    "    # Fitting the model\n",
    "    model = model.fit(smoothing_level = .1, smoothing_slope = .1, optimized = False)\n",
    "    \n",
    "    # Making predictions \n",
    "    yhat = model.predict(start = validate.index[0], end = validate.index[-1])\n",
    "    \n",
    "    yhat_df[col] = round(yhat, 0)\n",
    "    \n",
    "for col in train.columns:\n",
    "        eval_df = append_eval_df(model_type = 'Holts L=.1 S=.1', target_var = col)\n",
    "        plot_and_eval(target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_df = eval_df[eval_df.model_type != 'Holts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Based on Previous Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all the 2016 data points, compute the daily delta, year-over-year, average that delta over all the days, and adding that average to the previous year's value on a day will give you the forecast for that day. \n",
    "\n",
    "If a primary cycle is weekly, then you may want to do this on a week-over-week cadence. \n",
    "\n",
    "In the below example:  \n",
    "1. Compute the 365 average year over year differences from 2013 through 2015\n",
    "2. Add that average delta to the values during 2015. \n",
    "3. Set the index in your yhat dataframe to represent the dates those predictions are make for. \n",
    "\n",
    "Let's get started....\n",
    "\n",
    "**Re-split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:'2015']\n",
    "validate = df['2016']\n",
    "test = df['2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year difference\n",
    "train.diff(365).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the values for each day in 2015 and add the average year over year(yoy)(y/y)\n",
    "yhat_df = train['2015'] + train.diff(365).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set yhat_df to index of validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = yhat_df.set_index(validate.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values('rmse').groupby('target_var').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set yhat_df to index of validate\n",
    "yhat_df = yhat_df.set_index(validate.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set yhat_df to index of validate\n",
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'yoy-diff', target_var = col)\n",
    "    plot_and_eval(target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.concat([yhat_df.item_sold, validate.item_sold], axis = 1)\n",
    "compare_df.columns = ['yhat_items', 'actual_items']\n",
    "compare_df['error'] = compare_df.actual_items - compare_df.yhat_items\n",
    "compare_df['squared_error'] = compare_df.error * compare_df.error\n",
    "#compare_df[compare_df.squared_error.mean()]\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Which model did the best? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the min rmse for each variable\n",
    "\n",
    "\n",
    "# filter only the rows that match those rmse to find out \n",
    "# which models are best thus far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out on our out-of-sample data\n",
    "\n",
    "We will be using train + validate to predict test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must use same parameters we used from train\n",
    "yhat_ = validate + train.diff(365).mean()\n",
    "\n",
    "# set index to that of test\n",
    "yhat_df.index = test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)\n",
    "    append_eval_df(model_type = 'yoy-diff-test', target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "The end result of this exercise should be a Jupyter notebook named `model`.\n",
    "\n",
    "Using [saas.csv](https://ds.codeup.com/saas.csv) or log data from API usage or store_item_sales\n",
    "\n",
    "1. Split data (train/validate/test) and resample by any period, except daily, and aggregate using the sum. \n",
    "2. Forecast, plot and evaluate using each of the 4 parametric based methods we discussed:\n",
    "    - Simple Average\n",
    "    - Moving Average\n",
    "    - Holt's Linear Trend Model\n",
    "    - Based on previous year/month/etc., this is up to you.\n",
    "\n",
    "Optional: Using store item demand\n",
    "\n",
    "1. Predict 2018 total **monthly** sales for a single store and/or item by creating a model.\n",
    "2. Return a dataframe with the month, store_id, y-hat, and the confidence intervals (y-hat lower, y-hat upper).\n",
    "3. Plot the 2018 monthly sales predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
